{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "parliamentary-trance",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-sending",
   "metadata": {},
   "source": [
    "## 1). Implement the decision tree learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-evidence",
   "metadata": {},
   "source": [
    "The decision tree's node is consistute by decision node, which is making branching choice by conditions, and leaf node, which is no child node but shows the final decison result.\n",
    "Classification and Regression Tree(CART) algorithm is not only using by classification but also regression. For classification, CART use target which is discrete type and select feature by Gini index which is different with ID3 information gain rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "third-finish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# build a decision tree\n",
    "class DecisionTree():\n",
    "    def __init__(self, maxDepth, minSplits):\n",
    "        self.max_depth = maxDepth\n",
    "        self.min_splits = minSplits\n",
    "        \n",
    "    def fit(self, f, l):\n",
    "        self.feature = f\n",
    "        self.label = l\n",
    "        self.data = np.column_stack((self.feature, self.label)) # combine two matrix\n",
    "        self.buildTree()\n",
    "        #self.printTree(self.root)\n",
    "    \n",
    "    # calculate Gini index\n",
    "    def giniIndex(self, datas, labels):\n",
    "        num = sum([len(data) for data in datas]) # get the number of samples\n",
    "        gini = 0.0\n",
    "        \n",
    "        for data in datas:\n",
    "            size = float(len(data))\n",
    "            score = 0.0\n",
    "            if size == 0: # just in case divide by 0\n",
    "                continue\n",
    "            for label in labels:\n",
    "                pro = [i[-1] for i in data].count(label) / size\n",
    "                score += (pro ** 2)\n",
    "            # weight the score by relative size\n",
    "            gini += (1.0 - score) * (size / float(num))\n",
    "        return gini\n",
    "    \n",
    "    # to determine when we should stop: in the max depth or min node\n",
    "    def terminalNode(self, datas):\n",
    "        out = [data[-1] for data in datas]\n",
    "        return max(set(out), key=out.count)\n",
    "    \n",
    "    # split a dataset based on feature or feature label\n",
    "    def getSplit(self, index, val, datas):\n",
    "        left, right = list(), list()\n",
    "        for data in datas:\n",
    "            if data[index] <= val:\n",
    "                left.append(data)\n",
    "            else:\n",
    "                right.append(data)\n",
    "        return left, right\n",
    "    \n",
    "    # select the best split for dataset\n",
    "    def bestSplit(self, datas):\n",
    "        labels = list(set(data[-1] for data in datas))\n",
    "        best_index, best_value, best_score, best_datas = float('inf'), float('inf'), float('inf'), None\n",
    "        for i in range(len(datas[0])-1):\n",
    "            for data in datas:\n",
    "                values = self.getSplit(i, data[i], datas)\n",
    "                gini = self.giniIndex(values, labels)\n",
    "                if gini < best_score:\n",
    "                    best_index, best_value, best_score, best_datas = i, data[i], gini, values\n",
    "        return {'index': best_index, 'value': best_value, 'data': best_datas}\n",
    "    \n",
    "    # split node or make terminal\n",
    "    def splitBranch(self, node, depth):\n",
    "        left, right = node['data']\n",
    "        del(node['data'])\n",
    "        \n",
    "        # check in case no left or right, then no split\n",
    "        if not left or not right:\n",
    "            node['left'] = node['right'] = self.terminalNode(left + right)\n",
    "            return\n",
    "        # check max depth\n",
    "        if depth >= self.max_depth:\n",
    "            node['left'], node['right'] = self.terminalNode(left), self.terminalNode(right)\n",
    "            return\n",
    "        \n",
    "        # split left child\n",
    "        if len(left) <= self.min_splits:\n",
    "            node['left'] = self.terminalNode(left)\n",
    "        else:\n",
    "            node['left'] = self.bestSplit(left)\n",
    "            self.splitBranch(node['left'], depth+1)\n",
    "        \n",
    "        # split right child\n",
    "        if len(right) <= self.min_splits:\n",
    "            node['right'] = self.terminalNode(right)\n",
    "        else:\n",
    "            node['right'] = self.bestSplit(right)\n",
    "            self.splitBranch(node['right'], depth+1)\n",
    "    \n",
    "    # build a decision tree\n",
    "    def buildTree(self):\n",
    "        self.root = self.bestSplit(self.data)\n",
    "        self.splitBranch(self.root, 1)\n",
    "        return self.root\n",
    "    \n",
    "    # print a decision tree\n",
    "    def printTree(self, node, depth=0):\n",
    "        if isinstance(node, dict):\n",
    "            print('%s[X%d < %.2f]' %((depth*' ', (node['index']+1), node['value'])))\n",
    "            self.printTree(node['left'], depth+1)\n",
    "            self.printTree(node['right'], depth+1)\n",
    "        else:\n",
    "            print('%s[depth:%s]' %((depth*' ', depth+1)))\n",
    "    \n",
    "    # make a prediction\n",
    "    def predict_helper(self, node, data):\n",
    "        if data[node['index']] < node['value']:\n",
    "            if isinstance(node['left'], dict):\n",
    "                return self.predict_helper(node['left'], data)\n",
    "            else:\n",
    "                return node['left']\n",
    "        else:\n",
    "            if isinstance(node['right'], dict):\n",
    "                return self.predict_helper(node['right'], data)\n",
    "            else:\n",
    "                return node['right']\n",
    "    \n",
    "    # classification algorithm\n",
    "    def predict(self, testData):\n",
    "        self.pred_label = np.array([])\n",
    "        for data in testData:\n",
    "            self.pred_label = np.append(self.pred_label, self.predict_helper(self.root, data))\n",
    "        return self.pred_label\n",
    "\n",
    "\n",
    "#def accuracy(pred, actual):\n",
    "    #correct = 0\n",
    "    #num = len(pred)\n",
    "    \n",
    "    #for i in range(num):\n",
    "        #if int(pred[i] == actual[i]):\n",
    "            #correct += 1\n",
    "    #return correct / num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-accident",
   "metadata": {},
   "source": [
    "## 2). Run algorithm on the Iris flower data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "detailed-nepal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "# read the data\n",
    "iris = load_iris()\n",
    "# get the features and labels\n",
    "features, labels = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "artistic-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "certain-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_model = DecisionTree(maxDepth=5, minSplits=10)\n",
    "decision_tree_model.fit(train_features, train_labels)\n",
    "prediction = decision_tree_model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "documented-performer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#print('Model Accuracy: %.2f'% accuracy(prediction, y_test))\n",
    "print('Model Accuracy: %.2f'% accuracy_score(test_labels, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-banner",
   "metadata": {},
   "source": [
    "## 3). Run from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "arctic-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build CRAT decision tree\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(criterion='gini')\n",
    "# training\n",
    "clf = clf.fit(train_features, train_labels)\n",
    "#tree.plot_tree(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "exposed-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting\n",
    "test_pred = clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "statewide-chart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "# compare the predicted result with actual result\n",
    "score = accuracy_score(test_labels, test_pred)\n",
    "print(\"CART accuracy: %.2lf\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-newfoundland",
   "metadata": {},
   "source": [
    "# Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-policy",
   "metadata": {},
   "source": [
    "## Consider training a binary decision tree using entropy splits. \n",
    "       \n",
    "1. Prove that the decrease in entropy by a split on a binary yes/no feature can never be greater than 1 bit. \n",
    "Answer: As we learned from lecture, the entrtopy formula is $H(S) = \\sum_{x\\in X} -p(x)\\log_2 p(x)$. We could find that the $p(x)$ would determines the value of $H(s)$, so it will make H(s) = 0 if all splited nodes value are same. If the node value is euqally splited, then the entropy will be 1. For other situation, the entropy should between 0 and 1. Therefore, it can never be greater than 1 bit.\n",
    " \n",
    "\n",
    "2. Generalize this result to the case of arbitrary multiway branching. \n",
    "Answer: The entropy formula remains the same and the result is still true. If all splited nodes value are same, the entropy will be 0. If the node value is euqally splited, then the entropy will be 1. For other situation, the entropy should between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-express",
   "metadata": {},
   "source": [
    "# House Prices Prediction Using Regression Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-africa",
   "metadata": {},
   "source": [
    "## 1. Explore the data set and display summary statistics of the data. What can you learn from it on the data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "suburban-question",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('housing.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "likely-utility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<1H OCEAN     9136\n",
      "INLAND        6551\n",
      "NEAR OCEAN    2658\n",
      "NEAR BAY      2290\n",
      "ISLAND           5\n",
      "Name: ocean_proximity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"ocean_proximity\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "destroyed-slovakia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          longitude      latitude  housing_median_age   total_rooms  \\\n",
      "count  20640.000000  20640.000000        20640.000000  20640.000000   \n",
      "mean    -119.569704     35.631861           28.639486   2635.763081   \n",
      "std        2.003532      2.135952           12.585558   2181.615252   \n",
      "min     -124.350000     32.540000            1.000000      2.000000   \n",
      "25%     -121.800000     33.930000           18.000000   1447.750000   \n",
      "50%     -118.490000     34.260000           29.000000   2127.000000   \n",
      "75%     -118.010000     37.710000           37.000000   3148.000000   \n",
      "max     -114.310000     41.950000           52.000000  39320.000000   \n",
      "\n",
      "       total_bedrooms    population    households  median_income  \\\n",
      "count    20433.000000  20640.000000  20640.000000   20640.000000   \n",
      "mean       537.870553   1425.476744    499.539680       3.870671   \n",
      "std        421.385070   1132.462122    382.329753       1.899822   \n",
      "min          1.000000      3.000000      1.000000       0.499900   \n",
      "25%        296.000000    787.000000    280.000000       2.563400   \n",
      "50%        435.000000   1166.000000    409.000000       3.534800   \n",
      "75%        647.000000   1725.000000    605.000000       4.743250   \n",
      "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
      "\n",
      "       median_house_value  \n",
      "count        20640.000000  \n",
      "mean        206855.816909  \n",
      "std         115395.615874  \n",
      "min          14999.000000  \n",
      "25%         119600.000000  \n",
      "50%         179700.000000  \n",
      "75%         264725.000000  \n",
      "max         500001.000000  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-virtue",
   "metadata": {},
   "source": [
    "First check if there are some missing value or other issues, we found that the data type of last feature \"ocean_proximity\" is not float. Print the description of float type features and usevalue_count to show \"ocean_proximity\" information. We could use the maximum and minimm values to determine whether the value of the variable exceeds a reasonable range in real world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-compound",
   "metadata": {},
   "source": [
    "## 2. Compute the correlation between each feature and the target median_house_value. Which features have strong correlation with the target? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "welcome-copper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median_house_value    1.000000\n",
      "median_income         0.688075\n",
      "total_rooms           0.134153\n",
      "housing_median_age    0.105623\n",
      "households            0.065843\n",
      "total_bedrooms        0.049686\n",
      "population           -0.024650\n",
      "longitude            -0.045967\n",
      "latitude             -0.144160\n",
      "Name: median_house_value, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#The df.corr() method displays the correlation between the columns\n",
    "corr = df.corr()\n",
    "print(corr['median_house_value'].sort_values(ascending=False), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-upset",
   "metadata": {},
   "source": [
    "According to the corralation number, we could find that the median_income have strong correlation with the median_house_value. Features total_rooms, housing_median_age, households, and total_bedrooms are positive correlation with median_house_value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-magnitude",
   "metadata": {},
   "source": [
    "## 3. Which actions do you need to take in order to prepare the data set for the learning algorithm? Identify at least four such actions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-sponsorship",
   "metadata": {},
   "source": [
    "1) Gathering the data: find several datasets which are public and free.\n",
    "\n",
    "2) Data cleaning: check if there are some data missing or other issues: including delete abnormal data and remove duplicate data.\n",
    "\n",
    "3) Feature extraction: make relations between features and extract the strong corrlation with the taget feature.\n",
    "\n",
    "4) Splitting the data into training and testing sets: split the data to 80-20 percent taning and testing sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-crazy",
   "metadata": {},
   "source": [
    "## 4. Clean the data set using the data preprocessing techniques such that dataset should be trainable. Show a sample of the data set before and after cleaning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "plastic-student",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "20635    False\n",
       "20636    False\n",
       "20637    False\n",
       "20638    False\n",
       "20639    False\n",
       "Length: 20640, dtype: bool"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there has duplicate data\n",
    "df.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "affiliated-variety",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longitude               0\n",
      "latitude                0\n",
      "housing_median_age      0\n",
      "total_rooms             0\n",
      "total_bedrooms        207\n",
      "population              0\n",
      "households              0\n",
      "median_income           0\n",
      "median_house_value      0\n",
      "ocean_proximity         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check if there has any Null value\n",
    "null_all = df.isnull().sum()\n",
    "print(null_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "treated-cowboy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longitude             0\n",
      "latitude              0\n",
      "housing_median_age    0\n",
      "total_rooms           0\n",
      "total_bedrooms        0\n",
      "population            0\n",
      "households            0\n",
      "median_income         0\n",
      "median_house_value    0\n",
      "ocean_proximity       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# use 0 to make up Null value\n",
    "fill_data = df.fillna(0)\n",
    "df = fill_data\n",
    "# check again\n",
    "null_all = df.isnull().sum()\n",
    "print(null_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "southeast-moore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0        -122.23     37.88                41.0        880.0           129.0   \n",
      "1        -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2        -122.24     37.85                52.0       1467.0           190.0   \n",
      "3        -122.25     37.85                52.0       1274.0           235.0   \n",
      "4        -122.25     37.85                52.0       1627.0           280.0   \n",
      "...          ...       ...                 ...          ...             ...   \n",
      "20635    -121.09     39.48                25.0       1665.0           374.0   \n",
      "20636    -121.21     39.49                18.0        697.0           150.0   \n",
      "20637    -121.22     39.43                17.0       2254.0           485.0   \n",
      "20638    -121.32     39.43                18.0       1860.0           409.0   \n",
      "20639    -121.24     39.37                16.0       2785.0           616.0   \n",
      "\n",
      "       population  households  median_income  \n",
      "0           322.0       126.0         8.3252  \n",
      "1          2401.0      1138.0         8.3014  \n",
      "2           496.0       177.0         7.2574  \n",
      "3           558.0       219.0         5.6431  \n",
      "4           565.0       259.0         3.8462  \n",
      "...           ...         ...            ...  \n",
      "20635       845.0       330.0         1.5603  \n",
      "20636       356.0       114.0         2.5568  \n",
      "20637      1007.0       433.0         1.7000  \n",
      "20638       741.0       349.0         1.8672  \n",
      "20639      1387.0       530.0         2.3886  \n",
      "\n",
      "[20640 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# since there is no duplicate, we don't need to drop any data\n",
    "# extract all rows and columns except target feature.\n",
    "#X = df[['longitude','latitude','housing_median_age','total_rooms','total_bedrooms','population','households','median_income']]\n",
    "x = df.drop(['median_house_value', 'ocean_proximity'], axis=1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ruled-hurricane",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       median_house_value\n",
      "0                452600.0\n",
      "1                358500.0\n",
      "2                352100.0\n",
      "3                341300.0\n",
      "4                342200.0\n",
      "...                   ...\n",
      "20635             78100.0\n",
      "20636             77100.0\n",
      "20637             92300.0\n",
      "20638             84700.0\n",
      "20639             89400.0\n",
      "\n",
      "[20640 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# extract the target feature \n",
    "y = df[['median_house_value']]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-michael",
   "metadata": {},
   "source": [
    "## 5. Extract at least two new features from the data set that have strong correlation with the target feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sweet-paintball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median_house_value    1.000000\n",
      "median_income         0.688075\n",
      "total_rooms           0.134153\n",
      "housing_median_age    0.105623\n",
      "Name: median_house_value, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display first three features are the most positively correlated with median_house_value\n",
    "print(corr['median_house_value'].sort_values(ascending=False)[:4], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "diagnostic-community",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       housing_median_age  total_rooms  median_income\n",
      "0                    41.0        880.0         8.3252\n",
      "1                    21.0       7099.0         8.3014\n",
      "2                    52.0       1467.0         7.2574\n",
      "3                    52.0       1274.0         5.6431\n",
      "4                    52.0       1627.0         3.8462\n",
      "...                   ...          ...            ...\n",
      "20635                25.0       1665.0         1.5603\n",
      "20636                18.0        697.0         2.5568\n",
      "20637                17.0       2254.0         1.7000\n",
      "20638                18.0       1860.0         1.8672\n",
      "20639                16.0       2785.0         2.3886\n",
      "\n",
      "[20640 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset = x.drop(['households','total_bedrooms','population','longitude','latitude'], 1)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-interpretation",
   "metadata": {},
   "source": [
    "## 6. Run linear regression on the transformed data set. Use 80% of the data set as your training set and 20% as your test set. Compute RMSE and R-Square score both on the training and the test tests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "controlled-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizes the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(x)\n",
    "#data_x = pd.DataFrame(X, columns=x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "moving-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data to 80% traning and 20% testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "disturbed-cheese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating and Training the Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sporting-seeking",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "handled-gothic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x217b98459c8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#test predictions by comparing with actual value (y_test)\n",
    "plt.scatter(y_test,predictions, c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "liberal-traffic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 68946.37763629333\n",
      "R-squared: 0.6382564434514031\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "# print RMSE and R-squared for testing set\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print('R-squared:', r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "supreme-foster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 69964.06611674232\n",
      "R-squared: 0.6335617026942261\n"
     ]
    }
   ],
   "source": [
    "# print RMSE and R-squared for training set\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_train, model.predict(X_train))))\n",
    "print('R-squared:', r2_score(y_train, model.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-prague",
   "metadata": {},
   "source": [
    "## 7. Does adding regularization improve the results (ridge regression in this case)? If yes, which value of lambda provides the best RMSE on the test set? If no, what is the reason for it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "familiar-mounting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Ridge(), param_grid={'alpha': [0.01, 0.1, 1, 10, 100]})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use GridSearchCV to check the best value of lambda\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge_regression = Ridge()\n",
    "param_ridge = {'alpha': list(10**i for i in range(-2,3))}\n",
    "r_gs = GridSearchCV(ridge_regression, param_grid=param_ridge)\n",
    "r_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "handled-adelaide",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 10}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the best lambda\n",
    "r_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "educated-prophet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=10)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the best param to train the model\n",
    "ridge_model = Ridge(alpha=10)\n",
    "ridge_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "unnecessary-guess",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ridge_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "still-drilling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 68955.34975346006\n",
      "R-squared: 0.6381622886353501\n"
     ]
    }
   ],
   "source": [
    "# print RMSE and R-squared for testing set\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, pred)))\n",
    "print('R-squared:', r2_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bulgarian-symbol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 69964.7068708835\n",
      "R-squared: 0.6335549907363685\n"
     ]
    }
   ],
   "source": [
    "# print RMSE and R-squared for training set\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_train, ridge_model.predict(X_train))))\n",
    "print('R-squared:', r2_score(y_train, ridge_model.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-reviewer",
   "metadata": {},
   "source": [
    "According to the data displayed, we could see the ridge regression in this case did not improve too much the results.The goal of the regularization (ridge regression in this case) is to avoid overfitting and thus better prediction on the independent. Since ridge regression didn;t improve model too much, I guess overfitting is not problem in here but is underfitting since we have much more samples than features and there features cannot predict very well, more complex model might predict better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-developer",
   "metadata": {},
   "source": [
    "## 8. Now replace linear regression with DecisionTreeRegressor (in sklearn. tree). What is the RMSE on the training and test this time? Which phenomenon is observed here? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "first-comment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dtr = DecisionTreeRegressor()\n",
    "dtr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "technological-norfolk",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr_pred = dtr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "sublime-glenn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 65945.98275235524\n",
      "R-squared: 0.669055943506331\n"
     ]
    }
   ],
   "source": [
    "# print RMSE and R-squared for testing set\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, dtr_pred)))\n",
    "print('R-squared:', r2_score(y_test, dtr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "speaking-demographic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0\n",
      "R-squared: 1.0\n"
     ]
    }
   ],
   "source": [
    "# print RMSE and R-squared for training set\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_train, dtr.predict(X_train))))\n",
    "print('R-squared:', r2_score(y_train, dtr.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-spelling",
   "metadata": {},
   "source": [
    "The DecisionTreeRegressor did improve our results a little but the model is still underfitting. Next step we might try to combine some features or try more complex model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
